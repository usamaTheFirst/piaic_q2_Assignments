{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXgJ6uT1NydQ"
   },
   "source": [
    "Assignment: Flowers Recognition <br>\n",
    "Dataset Description:<br>\n",
    "\n",
    "This dataset contains 4242 images of flowers.<br>\n",
    "The data collection is based on the data flicr, google images, yandex images.<br>\n",
    "You can use this datastet to recognize plants from the photo.<br>\n",
    "\n",
    "Attribute Information:<br>\n",
    "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
    "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
    "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
    "This is a Multiclass Classification Problem.<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vy-ktuOKJH"
   },
   "source": [
    "WORKFLOW : <br>\n",
    "Load Data <br>\n",
    "Split into 60 and 40 ratio.<br>\n",
    "Encode labels.<br>\n",
    "Create Model<br>\n",
    "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
    "Train the Model.<br>\n",
    "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
    "Prediction should be > 85%<br>\n",
    "Evaluation Step<br>\n",
    "Prediction<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri3Bg5qfPRic"
   },
   "source": [
    "Data : <br>\n",
    "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hTtg3WuGTA1o"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1.0/255,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6055 images belonging to 6 classes.\n",
      "Found 2591 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "training_Data = train_data_gen.flow_from_directory(\n",
    "    r\"C:\\Users\\usama\\OneDrive\\Desktop\\sel\\AI-Q2-learning-resources\\DLAssignments\\data\\flowers\",\n",
    "    target_size=(150,150), \n",
    "    batch_size=5,\n",
    "    shuffle=True,\n",
    "     subset=\"training\",\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_Data = train_data_gen.flow_from_directory(\n",
    "    r\"C:\\Users\\usama\\OneDrive\\Desktop\\sel\\AI-Q2-learning-resources\\DLAssignments\\data\\flowers\",\n",
    "    target_size=(150,150),\n",
    "    batch_size=5,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "     subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.10980393, 0.10980393, 0.10980393],\n",
       "          [0.10980393, 0.10980393, 0.10980393],\n",
       "          [0.10980393, 0.10980393, 0.10980393],\n",
       "          ...,\n",
       "          [0.1137255 , 0.10588236, 0.10980393],\n",
       "          [0.1137255 , 0.10588236, 0.10980393],\n",
       "          [0.1137255 , 0.10588236, 0.10980393]],\n",
       " \n",
       "         [[0.1137255 , 0.1137255 , 0.1137255 ],\n",
       "          [0.10980393, 0.10980393, 0.11764707],\n",
       "          [0.1137255 , 0.1137255 , 0.12156864],\n",
       "          ...,\n",
       "          [0.1137255 , 0.10588236, 0.10980393],\n",
       "          [0.1137255 , 0.10588236, 0.10980393],\n",
       "          [0.1137255 , 0.10588236, 0.10980393]],\n",
       " \n",
       "         [[0.1137255 , 0.10980393, 0.12941177],\n",
       "          [0.1137255 , 0.10980393, 0.12941177],\n",
       "          [0.1137255 , 0.10980393, 0.12941177],\n",
       "          ...,\n",
       "          [0.1137255 , 0.10588236, 0.10980393],\n",
       "          [0.1137255 , 0.10588236, 0.10980393],\n",
       "          [0.1137255 , 0.10588236, 0.10980393]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.16862746, 0.16862746, 0.20784315],\n",
       "          [0.16078432, 0.16078432, 0.20000002],\n",
       "          [0.15686275, 0.15686275, 0.19607845],\n",
       "          ...,\n",
       "          [0.1137255 , 0.10588236, 0.10980393],\n",
       "          [0.10980393, 0.10196079, 0.10588236],\n",
       "          [0.1254902 , 0.12156864, 0.1137255 ]],\n",
       " \n",
       "         [[0.16470589, 0.16470589, 0.20392159],\n",
       "          [0.15686275, 0.15686275, 0.19607845],\n",
       "          [0.16078432, 0.16078432, 0.20000002],\n",
       "          ...,\n",
       "          [0.1137255 , 0.10588236, 0.10980393],\n",
       "          [0.10980393, 0.10196079, 0.10588236],\n",
       "          [0.1254902 , 0.1254902 , 0.11764707]],\n",
       " \n",
       "         [[0.16470589, 0.15686275, 0.20784315],\n",
       "          [0.14901961, 0.16078432, 0.19607845],\n",
       "          [0.15686275, 0.14901961, 0.19215688],\n",
       "          ...,\n",
       "          [0.10196079, 0.10196079, 0.10196079],\n",
       "          [0.1137255 , 0.10588236, 0.10980393],\n",
       "          [0.14117648, 0.13725491, 0.12941177]]],\n",
       " \n",
       " \n",
       "        [[[0.21568629, 0.20784315, 0.21176472],\n",
       "          [0.21176472, 0.20784315, 0.20000002],\n",
       "          [0.21176472, 0.20784315, 0.20000002],\n",
       "          ...,\n",
       "          [0.09803922, 0.13333334, 0.12156864],\n",
       "          [0.09411766, 0.13725491, 0.1137255 ],\n",
       "          [0.09803922, 0.14117648, 0.11764707]],\n",
       " \n",
       "         [[0.20392159, 0.20000002, 0.19215688],\n",
       "          [0.20000002, 0.19607845, 0.18823531],\n",
       "          [0.19215688, 0.19607845, 0.1764706 ],\n",
       "          ...,\n",
       "          [0.10196079, 0.13725491, 0.11764707],\n",
       "          [0.10196079, 0.14509805, 0.12156864],\n",
       "          [0.10196079, 0.14509805, 0.12156864]],\n",
       " \n",
       "         [[0.19215688, 0.18823531, 0.17254902],\n",
       "          [0.18431373, 0.18823531, 0.16862746],\n",
       "          [0.1764706 , 0.18039216, 0.16078432],\n",
       "          ...,\n",
       "          [0.10196079, 0.13725491, 0.11764707],\n",
       "          [0.10196079, 0.14509805, 0.1137255 ],\n",
       "          [0.10588236, 0.14901961, 0.11764707]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.16862746, 0.17254902, 0.11764707],\n",
       "          [0.18823531, 0.18039216, 0.12941177],\n",
       "          [0.20000002, 0.18431373, 0.13725491],\n",
       "          ...,\n",
       "          [0.17254902, 0.14117648, 0.18431373],\n",
       "          [0.17254902, 0.14117648, 0.18431373],\n",
       "          [0.1764706 , 0.14509805, 0.18823531]],\n",
       " \n",
       "         [[0.16470589, 0.16862746, 0.1137255 ],\n",
       "          [0.18039216, 0.18431373, 0.12941177],\n",
       "          [0.20000002, 0.19215688, 0.14117648],\n",
       "          ...,\n",
       "          [0.17254902, 0.14117648, 0.18431373],\n",
       "          [0.16862746, 0.13725491, 0.18039216],\n",
       "          [0.17254902, 0.14117648, 0.18431373]],\n",
       " \n",
       "         [[0.16078432, 0.16470589, 0.10980393],\n",
       "          [0.18039216, 0.18431373, 0.12941177],\n",
       "          [0.20000002, 0.19215688, 0.14117648],\n",
       "          ...,\n",
       "          [0.16862746, 0.13725491, 0.18039216],\n",
       "          [0.16862746, 0.13725491, 0.18039216],\n",
       "          [0.17254902, 0.14117648, 0.18431373]]],\n",
       " \n",
       " \n",
       "        [[[0.67058825, 0.43137258, 0.20784315],\n",
       "          [0.6745098 , 0.43921572, 0.19607845],\n",
       "          [0.7019608 , 0.46274513, 0.20784315],\n",
       "          ...,\n",
       "          [0.48627454, 0.15294118, 0.        ],\n",
       "          [0.47450984, 0.10196079, 0.02352941],\n",
       "          [0.5764706 , 0.18823531, 0.06666667]],\n",
       " \n",
       "         [[0.6784314 , 0.43921572, 0.21568629],\n",
       "          [0.67058825, 0.4431373 , 0.19607845],\n",
       "          [0.69411767, 0.45882356, 0.21176472],\n",
       "          ...,\n",
       "          [0.47058827, 0.13333334, 0.        ],\n",
       "          [0.4784314 , 0.10588236, 0.02745098],\n",
       "          [0.6117647 , 0.22352943, 0.09803922]],\n",
       " \n",
       "         [[0.6862745 , 0.454902  , 0.21960786],\n",
       "          [0.67058825, 0.43921572, 0.20392159],\n",
       "          [0.6901961 , 0.46274513, 0.21176472],\n",
       "          ...,\n",
       "          [0.45098042, 0.10980393, 0.        ],\n",
       "          [0.49411768, 0.12156864, 0.03529412],\n",
       "          [0.654902  , 0.27058825, 0.13333334]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.12156864, 0.24313727, 0.32156864],\n",
       "          [0.11764707, 0.19607845, 0.2901961 ],\n",
       "          [0.14509805, 0.1764706 , 0.2509804 ],\n",
       "          ...,\n",
       "          [0.4666667 , 0.04705883, 0.07058824],\n",
       "          [0.45098042, 0.03921569, 0.05882353],\n",
       "          [0.39607847, 0.04313726, 0.04313726]],\n",
       " \n",
       "         [[0.07450981, 0.17254902, 0.2509804 ],\n",
       "          [0.05882353, 0.10588236, 0.20784315],\n",
       "          [0.06666667, 0.10980393, 0.227451  ],\n",
       "          ...,\n",
       "          [0.5176471 , 0.02745098, 0.05882353],\n",
       "          [0.5019608 , 0.03137255, 0.06666667],\n",
       "          [0.4156863 , 0.03921569, 0.04313726]],\n",
       " \n",
       "         [[0.03921569, 0.10980393, 0.20392159],\n",
       "          [0.03137255, 0.06666667, 0.18039216],\n",
       "          [0.02745098, 0.08235294, 0.23529413],\n",
       "          ...,\n",
       "          [0.5254902 , 0.01568628, 0.04705883],\n",
       "          [0.52156866, 0.03137255, 0.0627451 ],\n",
       "          [0.4666667 , 0.03529412, 0.04705883]]],\n",
       " \n",
       " \n",
       "        [[[0.9803922 , 0.87843144, 0.09803922],\n",
       "          [0.9725491 , 0.8352942 , 0.02745098],\n",
       "          [0.96470594, 0.86274517, 0.15294118],\n",
       "          ...,\n",
       "          [0.45098042, 0.63529414, 0.        ],\n",
       "          [0.3647059 , 0.5686275 , 0.03137255],\n",
       "          [0.45882356, 0.6392157 , 0.04705883]],\n",
       " \n",
       "         [[0.9803922 , 0.87843144, 0.01176471],\n",
       "          [0.96470594, 0.81568635, 0.00392157],\n",
       "          [0.9568628 , 0.81568635, 0.03137255],\n",
       "          ...,\n",
       "          [0.43921572, 0.6431373 , 0.07450981],\n",
       "          [0.4784314 , 0.6431373 , 0.15686275],\n",
       "          [0.44705886, 0.6431373 , 0.02745098]],\n",
       " \n",
       "         [[0.9803922 , 0.8941177 , 0.        ],\n",
       "          [0.9686275 , 0.8078432 , 0.00784314],\n",
       "          [0.96470594, 0.8862746 , 0.5137255 ],\n",
       "          ...,\n",
       "          [0.5058824 , 0.6627451 , 0.3254902 ],\n",
       "          [0.43921572, 0.62352943, 0.07450981],\n",
       "          [0.4666667 , 0.64705884, 0.06666667]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.95294124, 0.89019614, 0.65882355],\n",
       "          [0.86666673, 0.8000001 , 0.49411768],\n",
       "          [0.85098046, 0.7568628 , 0.16078432],\n",
       "          ...,\n",
       "          [0.18039216, 0.39607847, 0.27450982],\n",
       "          [0.22352943, 0.427451  , 0.03137255],\n",
       "          [0.38431376, 0.19607845, 0.00392157]],\n",
       " \n",
       "         [[0.9607844 , 0.91372555, 0.6313726 ],\n",
       "          [0.882353  , 0.76470596, 0.03529412],\n",
       "          [0.8470589 , 0.7372549 , 0.1764706 ],\n",
       "          ...,\n",
       "          [0.05490196, 0.30588236, 0.        ],\n",
       "          [0.47450984, 0.31764707, 0.34901962],\n",
       "          [0.5254902 , 0.17254902, 0.07058824]],\n",
       " \n",
       "         [[0.9450981 , 0.882353  , 0.5411765 ],\n",
       "          [0.9058824 , 0.77647066, 0.01960784],\n",
       "          [0.8235295 , 0.7294118 , 0.14901961],\n",
       "          ...,\n",
       "          [0.07058824, 0.37647063, 0.        ],\n",
       "          [0.2627451 , 0.08627451, 0.07450981],\n",
       "          [0.50980395, 0.1254902 , 0.07450981]]],\n",
       " \n",
       " \n",
       "        [[[0.34901962, 0.18431373, 0.23137257],\n",
       "          [0.09019608, 0.07843138, 0.04313726],\n",
       "          [0.07058824, 0.07058824, 0.03921569],\n",
       "          ...,\n",
       "          [0.18431373, 0.21960786, 0.09803922],\n",
       "          [0.10196079, 0.20392159, 0.05882353],\n",
       "          [0.1254902 , 0.20000002, 0.09019608]],\n",
       " \n",
       "         [[0.09411766, 0.10196079, 0.09803922],\n",
       "          [0.08235294, 0.08627451, 0.05490196],\n",
       "          [0.04313726, 0.07058824, 0.03921569],\n",
       "          ...,\n",
       "          [0.14509805, 0.1137255 , 0.0627451 ],\n",
       "          [0.32941177, 0.18039216, 0.1764706 ],\n",
       "          [0.16470589, 0.10588236, 0.08627451]],\n",
       " \n",
       "         [[0.05882353, 0.14117648, 0.07450981],\n",
       "          [0.15686275, 0.14901961, 0.09803922],\n",
       "          [0.02352941, 0.06666667, 0.01176471],\n",
       "          ...,\n",
       "          [0.3019608 , 0.3254902 , 0.28627452],\n",
       "          [0.2392157 , 0.1254902 , 0.14509805],\n",
       "          [0.07843138, 0.07843138, 0.07058824]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.34117648, 0.07450981, 0.0627451 ],\n",
       "          [0.57254905, 0.0509804 , 0.07058824],\n",
       "          [0.5372549 , 0.06666667, 0.10196079],\n",
       "          ...,\n",
       "          [0.14117648, 0.20784315, 0.        ],\n",
       "          [0.1137255 , 0.12941177, 0.07058824],\n",
       "          [0.07843138, 0.10980393, 0.0509804 ]],\n",
       " \n",
       "         [[0.6039216 , 0.0627451 , 0.12156864],\n",
       "          [0.6117647 , 0.09019608, 0.10980393],\n",
       "          [0.49803925, 0.14509805, 0.14509805],\n",
       "          ...,\n",
       "          [0.42352945, 0.5686275 , 0.0627451 ],\n",
       "          [0.03921569, 0.0509804 , 0.02352941],\n",
       "          [0.04313726, 0.03529412, 0.03921569]],\n",
       " \n",
       "         [[0.65882355, 0.08235294, 0.12156864],\n",
       "          [0.67058825, 0.0627451 , 0.1254902 ],\n",
       "          [0.40784317, 0.05882353, 0.07450981],\n",
       "          ...,\n",
       "          [0.21960786, 0.34509805, 0.01176471],\n",
       "          [0.22352943, 0.30588236, 0.08235294],\n",
       "          [0.0627451 , 0.07450981, 0.10980393]]]], dtype=float32),\n",
       " array([[0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(training_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOdels with COnv2D and Maxpooling\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 20s 1s/step - loss: 1.3772 - accuracy: 0.6100 - val_loss: 2.5955 - val_accuracy: 0.5800\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 19s 977ms/step - loss: 1.5826 - accuracy: 0.5400 - val_loss: 1.7471 - val_accuracy: 0.4300\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 22s 1s/step - loss: 1.4909 - accuracy: 0.5300 - val_loss: 1.6551 - val_accuracy: 0.4400\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 19s 951ms/step - loss: 1.5237 - accuracy: 0.4900 - val_loss: 2.5486 - val_accuracy: 0.4900\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 19s 955ms/step - loss: 1.3300 - accuracy: 0.6400 - val_loss: 1.4432 - val_accuracy: 0.4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a1ad37ac0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit(\n",
    "    training_Data,\n",
    "    steps_per_epoch = 20,\n",
    "    validation_data = validation_Data, \n",
    "    validation_steps = 20,\n",
    "    epochs = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05727686, 0.04244211, 0.41518188, 0.21432948, 0.05480469,\n",
       "        0.21596493],\n",
       "       [0.04756345, 0.03080783, 0.5991259 , 0.16977702, 0.03252721,\n",
       "        0.1201985 ],\n",
       "       [0.07372228, 0.06735736, 0.6037722 , 0.11689851, 0.03619682,\n",
       "        0.10205281],\n",
       "       ...,\n",
       "       [0.06921162, 0.06230898, 0.62529725, 0.11270798, 0.03284592,\n",
       "        0.09762829],\n",
       "       [0.07026519, 0.05647088, 0.49998802, 0.16950925, 0.0489492 ,\n",
       "        0.15481755],\n",
       "       [0.02615164, 0.01332266, 0.45392963, 0.28399056, 0.03571923,\n",
       "        0.18688631]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(validation_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flowers Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
